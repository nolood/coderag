# CodeRAG - Semantic Code Search

> CLI инструмент и MCP сервер для семантического поиска по кодовой базе

## Описание

**CodeRAG** - это мощный инструмент для семантического поиска по коду, который объединяет в себе векторный поиск на основе эмбеддингов и классический BM25 поиск по ключевым словам. Проект предоставляет удобный CLI интерфейс, MCP (Model Context Protocol) сервер для интеграции с LLM (например, Claude), а также веб-интерфейс для отладки и визуализации.

## Основные возможности

### 1. Семантический поиск кода
- **Векторный поиск**: использует эмбеддинги для понимания семантического смысла кода
- **BM25 поиск**: классический поиск по ключевым словам с использованием Tantivy
- **Гибридный поиск**: комбинирует оба подхода с помощью алгоритма Reciprocal Rank Fusion (RRF)
- Настраиваемые веса для векторного и BM25 поиска (по умолчанию 0.7 и 0.3)

### 2. MCP Server
Интеграция с LLM через Model Context Protocol:
- **Stdio транспорт**: для локального использования через CLI
- **HTTP/SSE транспорт**: для удаленного доступа и множественных клиентов
- Шесть инструментов для LLM:
  - `search` - семантический поиск кода с file header injection
  - `list_files` - просмотр индексированных файлов с поддержкой glob-паттернов
  - `get_file` - получение полного содержимого файла
  - **`find_symbol`** - поиск символов (функций, классов, переменных) по имени
  - **`list_symbols`** - список всех символов в конкретном файле
  - **`find_references`** - поиск всех использований символа в кодовой базе

### 3. Умная индексация
- **AST-based chunking**: разбиение кода на семантические блоки с использованием Tree-sitter
- Поддержка множества языков: Rust, Python, JavaScript, TypeScript, Go, Java, **C, C++**
- **Параллельная индексация**: 3-5x ускорение на многоядерных системах (300+ файлов/сек)
- Настраиваемый размер чанков (по умолчанию 512 токенов)
- Автоматическое слияние мелких блоков и разбиение крупных
- Сохранение контекста: номера строк, путь к файлу, язык программирования
- **File header injection**: первые 50 строк файла включаются в результаты поиска для контекста

### 4. Файловый мониторинг
- Автоматическое отслеживание изменений в файлах (watch mode)
- **Smart batch detection**: интеллектуальное определение массовых изменений (git операции, npm install)
- Debouncing для эффективной обработки множественных изменений
- Инкрементальное обновление индекса при изменении файлов
- Отслеживание создания, модификации и удаления файлов
- **Настраиваемые пороги**: количество файлов, скорость изменений, задержка сбора

### 5. Мультипроектная поддержка
- Глобальный реестр проектов в домашней директории пользователя
- Управление множеством кодовых баз через единый CLI
- Переключение между проектами с сохранением контекста
- Статистика по каждому проекту (файлы, чанки, размер индекса)

### 6. Веб-интерфейс
- Удобный UI для поиска и просмотра результатов
- Просмотр индексированных файлов
- Статистика индекса в реальном времени
- Метрики в формате Prometheus
- Возможность ре-индексации через веб-интерфейс

## Архитектура

### Технологический стек

#### Основные технологии
- **Rust** - язык программирования
- **Tokio** - асинхронный runtime
- **Clap** - CLI фреймворк

#### Векторный поиск и эмбеддинги
- **FastEmbed** - библиотека для генерации эмбеддингов (по умолчанию)
- **OpenAI API** - поддержка моделей OpenAI embedding (text-embedding-3-small, text-embedding-3-large)
- **LanceDB** - векторная база данных
- **Arrow** - формат данных для эффективного хранения

#### Поиск и индексация
- **Tree-sitter** - парсинг AST для умной сегментации кода
- **Tantivy** - полнотекстовый поиск (BM25)
- **Notify** - мониторинг файловой системы

#### MCP и веб-сервер
- **RMCP** - реализация Model Context Protocol
- **Axum** - веб-фреймворк
- **Tower-HTTP** - middleware (CORS, статические файлы)

#### Метрики и мониторинг
- **Prometheus** - экспорт метрик
- **Tracing** - структурированное логирование

### Модули проекта

```
src/
├── cli/           # CLI интерфейс и парсинг аргументов
├── commands/      # Реализация команд (init, index, search, serve, watch, web)
├── config/        # Конфигурация и настройки
├── embeddings/    # Генерация эмбеддингов (FastEmbed)
├── indexer/       # Чанкинг кода (AST и построчный)
├── mcp/           # MCP сервер (stdio и HTTP/SSE транспорты)
├── metrics/       # Prometheus метрики
├── registry/      # Глобальный реестр проектов
├── search/        # Поисковые движки (vector, BM25, hybrid)
├── storage/       # Работа с LanceDB
├── watcher/       # Мониторинг файловой системы
└── web/           # Веб-интерфейс
```

## Модели эмбеддингов

### Поддерживаемые провайдеры
- **FastEmbed** - быстрая Rust-реализация генерации эмбеддингов (по умолчанию)
- **OpenAI API** - поддержка облачных моделей OpenAI

### Поддерживаемые модели

#### FastEmbed модели
| Модель | Размерность | Описание |
|--------|-------------|----------|
| **nomic-embed-text-v1.5** | 768 | По умолчанию, отличный баланс качества и скорости |
| all-MiniLM-L6-v2 | 384 | Компактная и быстрая модель |
| bge-small-en-v1.5 | 384 | Малая модель BGE |
| bge-base-en-v1.5 | 768 | Базовая модель BGE |
| bge-large-en-v1.5 | 1024 | Большая модель BGE, максимальное качество |

#### OpenAI модели
| Модель | Размерность | Описание |
|--------|-------------|----------|
| **text-embedding-3-small** | 1536 | Экономичная модель с хорошим качеством |
| text-embedding-3-large | 3072 | Максимальное качество, больше размерность |
| text-embedding-ada-002 | 1536 | Предыдущее поколение, стабильная модель |

### Параметры
- **Размер батча**: 32 (по умолчанию)
- **Автоматическая загрузка**: FastEmbed модели скачиваются при первом запуске
- **Fallback**: при неизвестной модели используется nomic-embed-text-v1.5
- **API ключ OpenAI**: задается через переменную окружения `OPENAI_API_KEY`

## Алгоритм гибридного поиска

### Reciprocal Rank Fusion (RRF)

CodeRAG использует RRF для объединения результатов векторного и BM25 поиска:

```
score = Σ(weight / (k + rank))
```

Где:
- `weight` - вес для конкретного типа поиска (0.7 для векторного, 0.3 для BM25)
- `k` - константа RRF (по умолчанию 60)
- `rank` - позиция результата в списке (1-indexed)

### Преимущества гибридного подхода
- Сочетает семантическое понимание (векторный поиск) с точным совпадением (BM25)
- Улучшает релевантность при поиске специфических терминов
- Повышает recall за счет комбинирования двух методов

## CLI команды

### Инициализация и индексация
```bash
# Инициализировать CodeRAG в текущей директории
coderag init

# Проиндексировать кодовую базу
coderag index

# Отслеживать изменения и автоматически обновлять индекс
coderag watch [--debounce-ms 500]
```

### Поиск
```bash
# Поиск по кодовой базе
coderag search "поисковый запрос" [--limit 10]
```

### MCP сервер
```bash
# Запустить MCP сервер (stdio)
coderag serve

# Запустить MCP сервер (HTTP/SSE)
coderag serve --transport http --port 3000
```

### Мультипроектная поддержка
```bash
# Список всех проектов
coderag projects list

# Добавить текущую директорию как проект
coderag projects add <имя>

# Переключиться на проект
coderag projects switch <имя>

# Удалить проект из реестра
coderag projects remove <имя>

# Статус текущего проекта
coderag projects status
```

### Веб-интерфейс и статистика
```bash
# Запустить веб-интерфейс
coderag web [--port 8080]

# Показать статистику индекса
coderag stats

# Экспортировать метрики в формате Prometheus
coderag stats --prometheus
```

## Конфигурация

Конфигурационный файл `.coderag/config.toml`:

```toml
[indexer]
# Расширения файлов для индексации
extensions = ["rs", "py", "ts", "tsx", "js", "jsx", "go", "java", "c", "cpp", "cc", "cxx", "h", "hpp"]
# Паттерны игнорирования
ignore_patterns = ["node_modules", "target", ".git", "dist", "build"]
# Размер чанка в токенах
chunk_size = 512
# Стратегия чанкинга: "ast" или "line"
chunker_strategy = "ast"
# Минимальный размер чанка
min_chunk_tokens = 50
# Максимальный размер чанка
max_chunk_tokens = 1500
# Параллельные потоки (null для автоматического определения)
parallel_threads = 8
# Размер батча файлов
file_batch_size = 100
# Максимум одновременно обрабатываемых файлов
max_concurrent_files = 50

[embeddings]
# Провайдер эмбеддингов: "fastembed" или "openai"
provider = "fastembed"  # или "openai"

[embeddings.providers.fastembed]
# Модель эмбеддингов для FastEmbed
model = "nomic-embed-text-v1.5"
# Размер батча
batch_size = 32

[embeddings.providers.openai]
# API ключ OpenAI (можно использовать переменную окружения)
api_key = "${OPENAI_API_KEY}"
# Модель OpenAI
model = "text-embedding-3-small"
# Размер батча
batch_size = 100

[storage]
# Путь к базе данных (относительно .coderag/)
db_path = "index.lance"

[server]
# Тип транспорта: "stdio" или "http"
transport = "stdio"

[server.http]
# Хост для HTTP транспорта
host = "127.0.0.1"
# Порт для HTTP транспорта
port = 3000
# Путь для SSE
sse_path = "/sse"
# Путь для POST запросов
post_path = "/message"

[search]
# Режим поиска: "vector", "bm25", или "hybrid"
mode = "hybrid"
# Вес векторного поиска (0.0 - 1.0)
vector_weight = 0.7
# Вес BM25 поиска (0.0 - 1.0)
bm25_weight = 0.3
# Константа RRF
rrf_k = 60.0
# Количество результатов по умолчанию
default_limit = 10
# Включить file header injection
include_file_header = true
# Количество строк для file header
file_header_lines = 50

[watcher]
# Задержка debounce в миллисекундах
debounce_ms = 500

[watcher.mass_change]
# Порог количества файлов для определения массовых изменений
threshold_files = 50
# Порог скорости изменений (файлов в секунду)
threshold_rate = 20.0
# Задержка сбора изменений в миллисекундах
collection_delay_ms = 3000
```

## Метрики и мониторинг

### Prometheus метрики

CodeRAG экспортирует следующие метрики:

**Поисковые метрики:**
- `coderag_search_requests_total` - общее количество поисковых запросов
- `coderag_search_latency_seconds` - время выполнения поиска
- `coderag_search_results` - количество результатов на запрос

**Метрики индексации:**
- `coderag_indexed_files` - количество индексированных файлов
- `coderag_indexed_chunks` - количество чанков в индексе
- `coderag_index_latency_seconds` - время индексации

**Метрики эмбеддингов:**
- `coderag_embedding_requests_total` - количество запросов на генерацию эмбеддингов
- `coderag_embedding_latency_seconds` - время генерации эмбеддингов

## Использование с Claude

CodeRAG предоставляет MCP сервер для интеграции с Claude и другими LLM:

### Настройка в Claude Desktop

Добавьте в конфигурацию Claude (`~/Library/Application Support/Claude/claude_desktop_config.json`):

```json
{
  "mcpServers": {
    "coderag": {
      "command": "coderag",
      "args": ["serve"]
    }
  }
}
```

### Или с HTTP транспортом

```json
{
  "mcpServers": {
    "coderag": {
      "command": "coderag",
      "args": ["serve", "--transport", "http", "--port", "3000"]
    }
  }
}
```

## Преимущества

### Для разработчиков
- Быстрый поиск примеров использования функций и API
- Нахождение похожего кода для рефакторинга
- Изучение структуры незнакомого проекта
- Навигация по большим кодовым базам

### Для LLM (через MCP)
- Точный поиск релевантного контекста для генерации кода
- Понимание существующих паттернов в проекте
- Доступ к актуальному коду проекта
- Семантическое понимание кодовой базы

### Технические преимущества
- Написан на Rust - высокая производительность и безопасность
- Локальное выполнение - данные не покидают вашу машину
- Инкрементальное обновление - быстрая ре-индексация
- Гибридный поиск - лучшая релевантность результатов
- Масштабируемость - поддержка больших проектов

## Производительность

### Индексация
- **Последовательная**: ~100 файлов/сек
- **Параллельная**: 300+ файлов/сек (3-5x ускорение)
- **Строк кода**: ~1000-2000 строк/сек (зависит от модели эмбеддингов)
- **Параллельных потоков**: автоматическое определение или настраиваемое (1-16)

### Поиск
- **Семантический поиск**: <50ms типичная задержка
- **Symbol search**: <10ms для точного поиска
- **Гибридный поиск**: <100ms для большинства запросов
- **File header injection**: минимальные накладные расходы (<5ms)

### Память и хранение
- **RAM**: ~125MB для 500k символов
- **Индекс**: 100-500 MB для типичного проекта
- **LanceDB**: компактное хранение векторов с сжатием
- **Батчинг**: предотвращение OOM на больших кодовых базах

### Тестирование
- **150+ unit тестов**: покрытие основной функциональности
- **Integration тесты**: проверка полного цикла работы
- **Benchmark suite**: метрики качества поиска (precision, recall)
- **Per-language тесты**: проверка чанкинга для каждого языка

## Лицензия

MIT

## Репозиторий

https://github.com/nolood/coderag

## Версия

0.1.0

---

*CodeRAG - делает поиск по коду таким же естественным, как поиск в интернете*
